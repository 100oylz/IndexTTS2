[project]
name = "indextts2"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "accelerate>=1.10.1",
    "cn2an>=0.5.23",
    "cython>=3.1.4",
    "datasets>=4.2.0",
    "descript-audiotools>=0.7.2",
    "einops>=0.8.1",
    "ffmpeg-python>=0.2.0",
    "g2p-en>=2.1.0",
    "jieba>=0.42.1",
    "json5>=0.12.1",
    "keras>=3.11.3",
    "librosa>=0.11.0",
    "matplotlib>=3.10.7",
    "modelscope>=1.30.0",
    "munch>=4.0.0",
    "numba>=0.62.1",
    "numpy>=2.2.6",
    "omegaconf>=2.3.0",
    "openai>=2.6.0",
    "pandas>=2.3.3",
    "peft>=0.17.1",
    "safetensors>=0.6.2",
    "sentencepiece>=0.2.1",
    "tenacity>=9.1.2",
    "tensorboard>=2.20.0",
    "textstat>=0.7.10",
    "tiktoken>=0.12.0",
    "tokenizers==0.21.0",
    "tqdm>=4.67.1",
    "transformers==4.52.1",
    # Use "wetext" on Windows/Mac, otherwise "WeTextProcessing" on Linux.
    "transformers-stream-generator>=0.0.5",
    "wetext>=0.0.9; sys_platform != 'linux'",
    "WeTextProcessing; sys_platform == 'linux'",
    "xpinyin>=0.7.7",
]

[project.optional-dependencies]
cpu = [
  "torch>=2.7.0",
  "torchvision>=0.22.0",
  "torchaudio>=2.7.0",
]
cu126 = [
  "torch>=2.7.0",
  "torchvision>=0.22.0",
  "torchaudio>=2.7.0",
]

deepspeed = [
  "deepspeed==0.17.1",
]

[tool.uv]
conflicts = [
  [
    { extra = "cpu" },
    { extra = "cu126" },
  ],
]

[tool.uv.sources]
torch = [
  { index = "pytorch-cpu", extra = "cpu" },
  { index = "pytorch-cu126", extra = "cu126" },
]
torchvision = [
  { index = "pytorch-cpu", extra = "cpu" },
  { index = "pytorch-cu126", extra = "cu126" },
]
torchaudio = [
  { index = "pytorch-cpu", extra = "cpu" },
  { index = "pytorch-cu126", extra = "cu126" },
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true
