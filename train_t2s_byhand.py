# -*- coding: utf-8 -*-
"""
train_t2s_byhand.py
åªä¿®æ”¹æœ¬æ–‡ä»¶ï¼šåŸºäº UnifiedVoiceï¼ˆindextts.gpt.model_v2ï¼‰+ TextTokenizerï¼ˆindextts.utils.frontï¼‰
å®ç° IndexTTS2 çš„ä¸‰é˜¶æ®µ T2S è®­ç»ƒï¼ˆAR è¯­ä¹‰ token é¢„æµ‹ï¼‰ã€‚

æ•°æ®æœŸæœ›ï¼ˆJSONLï¼Œæ¯è¡Œä¸€ä¸ªæ ·æœ¬ï¼Œå­—æ®µå°½é‡é½å…¨ï¼›ç¼ºçœæ—¶è„šæœ¬ä¼šç»™â€œå¯è¿è¡Œçš„å…œåº•â€ï¼‰ï¼š
{
  "text": "å¿«èº²èµ·æ¥ï¼æ˜¯ä»–è¦æ¥äº†ï¼",
  "sem_tokens": [8192, 10, 33, ..., 8193],   # è¯­ä¹‰tokenåºåˆ—ï¼ˆè‹¥æœªå«<EA>/stopï¼Œè„šæœ¬ä¼šè¡¥ï¼‰
  "spk_id": 0,
  "cond_mel": [[... 1024ç»´ ...] x frames],   # æ¡ä»¶melç‰¹å¾ï¼Œå¯é€‰ï¼›æ— åˆ™èµ°é›¶å¼ é‡å…œåº•
  "emo_cond_mel": [[... 1024ç»´ ...] x frames],# æƒ…æ„Ÿæ¡ä»¶melï¼Œå¯é€‰ï¼›æ— åˆ™æ²¿ç”¨ cond_mel
  "T":  len(sem_tokens)                       # å¯é€‰ï¼›ç”¨äºâ€œæ—¶é•¿æ§åˆ¶å‘é‡â€pï¼ˆStage1å¯ç½®é›¶ï¼‰
}

é»˜è®¤è¯»å–ï¼š
  train.jsonl:  ./data/train.jsonl
  valid.jsonl:  ./data/val.jsonl
  è¯è¡¨(bpe):    ./checkpoints/bpe.model
"""

import os, json, math, random, argparse
from dataclasses import dataclass, asdict, field
from typing import Dict, Any, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

from torch.optim import AdamW, Adam, SGD, Adagrad
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils import clip_grad_norm_
from tqdm import tqdm

# ========= æ¥è‡ªä½ ä»“åº“çš„æ¨¡å‹ä¸åˆ†è¯å™¨ =========
from indextts.gpt.model_v2 import UnifiedVoice                    # ä½ çš„ UnifiedVoiceï¼ˆT2Sï¼‰
from indextts.utils.front import TextTokenizer, TextNormalizer     # æ–‡æœ¬ tokenizer

# ================== å¸¸é‡ & å·¥å…· ==================
PAD_ID = 0   # ç”¨äº sem/text paddingï¼ˆä¸ tokenizer çš„ pad åŒºåˆ†ï¼Œæ— å†²çªï¼‰
BOS_ID = 1   # å³ç§»èµ·å§‹ç¬¦ï¼ˆä»…ç”¨äº sem_inp çš„å ä½ï¼Œä¸ä¼šå†™å…¥æ¨¡å‹çš„ start_mel_tokenï¼‰
EA_ID  = 8193  # å¯¹åº” UnifiedVoice.stop_mel_tokenï¼Œä½œä¸ºè¯­ä¹‰tokenç»ˆæ­¢

def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)

def exists(p): return p is not None

def cosine_with_warmup(step, base_lr, warmup, max_steps, min_lr=1e-6):
    if step < warmup:
        return base_lr * step / max(1, warmup)
    ratio = (step - warmup) / max(1, max_steps - warmup)
    return min_lr + (base_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * ratio))


# ---------------------- å­é…ç½®ç±»ï¼ˆä¿æŒä¸å˜ï¼‰ ----------------------
@dataclass
class ConditionModules:
    output_size: int = 256
    linear_units: int = 2048
    attention_heads: int = 8
    num_blocks: int = 6
    input_layer: str = "conv2d"
    perceiver_mult: int = 4


@dataclass
class EmoConditionModule:
    output_size: int = 256
    linear_units: int = 2048
    attention_heads: int = 8
    num_blocks: int = 6
    input_layer: str = "conv2d"
    perceiver_mult: int = 4


# ---------------------- æ¨¡å‹é…ç½®ç±»ï¼ˆä¿æŒä¸å˜ï¼‰ ----------------------
@dataclass
class UnifiedVoiceConfig:
    layers: int = 8
    model_dim: int = 512
    heads: int = 8
    max_text_tokens: int = 1024
    max_mel_tokens: int = 1024
    max_conditioning_inputs: int = 1
    mel_length_compression: int = 1024
    start_text_token: int = 0
    stop_text_token: int = 1
    number_mel_codes: int = 8194
    start_mel_token: int = 8192
    stop_mel_token: int = 8193
    train_solo_embeddings: bool = False
    use_mel_codes_as_input: bool = True
    checkpointing: bool = True
    types: int = 1
    condition_num_latent: int = 32
    condition_type: str = "perceiver"
    condition_module: dict = field(
        default_factory=lambda: asdict(ConditionModules())
    )
    emo_condition_module: dict = field(
        default_factory=lambda: asdict(EmoConditionModule())
    )


# ---------------------- è®­ç»ƒè¶…å‚æ•°ç±»ï¼ˆå†»ç»“ï¼Œä¸å¯ä¿®æ”¹ï¼‰ ----------------------
@dataclass(frozen=True)  # frozen=True ä½¿ç±»å®ä¾‹ä¸å¯ä¿®æ”¹
class TrainHParams:
    """ç¥ç»ç½‘ç»œè®­ç»ƒè¶…å‚æ•°é…ç½®ç±»ï¼ˆé€‚é…T2Såœºæ™¯ï¼‰- å†»ç»“ä¸å¯ä¿®æ”¹"""
    # ---------------------- åŸºç¡€è®­ç»ƒé…ç½® ----------------------
    epochs: int = 100
    batch_size: int = 32
    val_batch_size: int = 64
    num_workers: int = 4
    pin_memory: bool = True
    seed:int=42
    # device ç”¨ default_factory ä¸”å†»ç»“ï¼Œç¡®ä¿è‡ªåŠ¨æ£€æµ‹åä¸å¯ä¿®æ”¹
    device: str = field(
        default_factory=lambda: "cuda:0" if torch.cuda.is_available() else "cpu",
        init=False  # ç¦æ­¢å®ä¾‹åŒ–æ—¶æ‰‹åŠ¨ä¼ å…¥ï¼ˆå¼ºåˆ¶è‡ªåŠ¨æ£€æµ‹ï¼‰
    )

    # ---------------------- ä¼˜åŒ–å™¨é…ç½® ----------------------
    optimizer_type: str = "adamw"
    learning_rate: float = 1e-4
    weight_decay: float = 1e-5
    betas: tuple = (0.9, 0.999)
    eps: float = 1e-8

    # ---------------------- è®­ç»ƒç¨³å®šæ€§é…ç½® ----------------------
    gradient_clip_norm: float = 1.0
    accumulation_steps: int = 1
    amp: bool = field(default=False, init=False)  # å¯é€šè¿‡å‘½ä»¤è¡Œ --amp æ‰“å¼€

    # ---------------------- æ•°æ®ç›¸å…³é…ç½® ----------------------
    vocab_file_path:str="./checkpoints/bpe.model"
    train_jsonl: str = "./data/train.jsonl"
    val_jsonl: str = "./data/val.jsonl"
    json_index_path: str = "./data/dataset_index.json"
    max_text_length: int = 1024
    max_mel_length: int = 1024
    audio_sample_rate: int = 16000
    speed_aug_range: List[float] = field(
        default_factory=lambda: [0.8, 1.0, 1.2],
        init=False
    )

    # ---------------------- æ­£åˆ™åŒ–é…ç½® ----------------------
    dropout_rate: float = 0.1

    # ---------------------- æ—¥å¿—ä¸ä¿å­˜é…ç½® ----------------------
    log_dir: str = "./logs"
    checkpoint_dir: str = "./checkpoints"
    save_freq: int = 1
    save_best_only: bool = True
    log_freq: int = 100
    val_freq: int = 5

    # ---------------------- æ—©åœé…ç½® ----------------------
    early_stop: bool = True
    early_stop_patience: int = 20
    monitor_metric: str = "val_loss"
    monitor_mode: str = "min"

# ================== æ•°æ®é›† & Collate ==================
class T2SDataset(Dataset):
    """
    è®­ç»ƒè¯­æ–™ï¼ˆJSONLï¼‰å­—æ®µï¼š
      - text: str
      - sem_tokens: List[int]ï¼ˆè‹¥æœ«å°¾æ—  EA_IDï¼Œæœ¬è„šæœ¬ä¼šè¡¥é½ï¼‰
      - spk_id: intï¼ˆå¯é€‰ï¼Œç”¨äº Stage2 çš„å¯¹æŠ—æ”¯è·¯ï¼‰
      - cond_mel: List[List[float]] å½¢çŠ¶ [frames, 1024] æˆ– [1024, frames]ï¼ˆäºŒè€…éƒ½æ¥å—ï¼‰
      - emo_cond_mel: åŒä¸Šï¼›å¯ç¼ºçœæ—¶å¤ç”¨ cond_mel
      - T: intï¼ˆå¯é€‰ï¼Œç›®æ ‡è¯­ä¹‰é•¿åº¦ï¼›Stage1æ„é€  p-vector å¯ç”¨ï¼›ç¼ºçœæ—¶ç”¨ len(sem_tokens)ï¼‰
    """
    def __init__(self, jsonl_path: str, tokenizer: TextTokenizer):
        self.tk = tokenizer
        self.items = []
        if not os.path.exists(jsonl_path):
            # å¯è¿è¡Œå…œåº•
            print(f"[WARN] {jsonl_path} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨å†…ç½®æ¼”ç¤ºæ ·æœ¬ã€‚")
            demo = {
                "text": "å¿«èº²èµ·æ¥ï¼æ˜¯ä»–è¦æ¥äº†ï¼",
                "sem_tokens": [8192, 10, 11, 12, 13, 8193],
                "spk_id": 0
            }
            self.items = [demo] * 64
            return
        with open(jsonl_path, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip(): continue
                eg = json.loads(line)
                self.items.append(eg)

    def __len__(self): return len(self.items)

    def __getitem__(self, idx):
        eg = self.items[idx]
        text_ids = self.tk.encode(eg.get("text", ""), out_type=int)

        sem = eg.get("sem_tokens", [])
        if len(sem) == 0 or sem[-1] != EA_ID:
            sem = sem + [EA_ID]
        T = eg.get("T", len(sem))

        spk = int(eg.get("spk_id", 0))

        def _to_mel(x):
            if x is None: return None
            arr = np.array(x, dtype=np.float32)
            if arr.ndim != 2:
                raise ValueError("cond_mel / emo_cond_mel å¿…é¡»æ˜¯2Dæ•°ç»„")
            # ç»Ÿä¸€ä¸º [1024, frames]
            if arr.shape[0] != 1024 and arr.shape[1] == 1024:
                arr = arr.T
            return arr  # [1024, frames]

        cond_mel = _to_mel(eg.get("cond_mel", None))
        emo_mel  = _to_mel(eg.get("emo_cond_mel", None))

        return {
            "text_ids": np.asarray(text_ids, dtype=np.int64),
            "sem": np.asarray(sem, dtype=np.int64),
            "T": int(T),
            "spk": spk,
            "cond_mel": cond_mel,   # [1024, F] or None
            "emo_mel": emo_mel      # [1024, F] or None
        }

def pad_1d(seqs, pad=PAD_ID, dtype=np.int64):
    mx = max(len(s) for s in seqs)
    arr = np.full((len(seqs), mx), pad, dtype=dtype)
    lens = np.array([len(s) for s in seqs], dtype=np.int64)
    for i, s in enumerate(seqs): arr[i, :len(s)] = s
    return torch.from_numpy(arr), torch.from_numpy(lens)

def collate_fn(batch: List[Dict[str, Any]]):
    text_list = [b["text_ids"] for b in batch]
    sem_list  = [b["sem"] for b in batch]
    text, text_len = pad_1d(text_list, pad=PAD_ID)
    sem,  sem_len  = pad_1d(sem_list,  pad=PAD_ID)

    spk = torch.tensor([b["spk"] for b in batch], dtype=torch.long)
    T   = torch.tensor([b["T"] for b in batch], dtype=torch.long)

    # å³ç§»è§£ç ç«¯è¾“å…¥ï¼šBOS + target[:-1]
    sem_inp = torch.cat([torch.full_like(sem[:, :1], BOS_ID), sem[:, :-1]], dim=1)

    # æ¡ä»¶ melï¼šå…œåº•ä¸ºé›¶å¼ é‡ï¼ˆå¯è¿è¡Œï¼‰
    def _pad_mel(key: str):
        lst = [b[key] for b in batch]
        F = max((x.shape[1] for x in lst if x is not None), default=50)
        out = []
        length = []
        for x in lst:
            if x is None:
                arr = np.zeros((1024, F), dtype=np.float32)
                L = F
            else:
                L = x.shape[1]
                if L < F:
                    pad = np.zeros((1024, F-L), dtype=np.float32)
                    arr = np.concatenate([x, pad], axis=1)
                else:
                    arr = x[:, :F]
                L = min(L, F)
            out.append(torch.from_numpy(arr))
            length.append(L)
        return torch.stack(out, dim=0), torch.tensor(length, dtype=torch.long)

    cond_mel, cond_len = _pad_mel("cond_mel")
    emo_mel,  emo_len  = _pad_mel("emo_mel")

    return {
        "text": text, "text_len": text_len,
        "sem_inp": sem_inp, "sem_tgt": sem, "sem_len": sem_len,
        "spk": spk, "T": T,
        "cond_mel": cond_mel, "cond_len": cond_len,
        "emo_mel": emo_mel, "emo_len": emo_len
    }


# ================== è®­ç»ƒå™¨ ==================
class T2STrainer:
    def __init__(self, stage: int = 1):
        self.hp = TrainHParams()
        set_seed(self.hp.seed)
        self.device = torch.device(self.hp.device)
        print(f"[Device] {self.device}")

        # Tokenizer
        normalizer = TextNormalizer()
        self.tokenizer = TextTokenizer(self.hp.vocab_file_path, normalizer)

        # æ¨¡å‹ï¼ˆâš ï¸å¼ºåˆ¶åˆ‡åˆ° perceiver æ¡ä»¶åˆ†æ”¯ï¼Œé¿å¼€ conformer+RPEï¼‰
        self.model_cfg = UnifiedVoiceConfig()
        _cfg = asdict(self.model_cfg)
        _cfg["condition_type"] = "perceiver"   # â† å…³é”®ï¼šç¨³å®šæ¡ä»¶åˆ†æ”¯
        self.model = UnifiedVoice(**_cfg).to(self.device)

        # ä¼˜åŒ–å™¨
        self.optimizer = self._build_optimizer()

        self.stage = int(stage)
        self.global_step = 0
        self.best_val = float("inf")

        os.makedirs(self.hp.checkpoint_dir, exist_ok=True)

    def _build_optimizer(self):
        p = [q for q in self.model.parameters() if q.requires_grad]
        t = self.hp.optimizer_type.lower()
        if t == "adamw":
            return AdamW(p, lr=self.hp.learning_rate, betas=self.hp.betas, eps=self.hp.eps, weight_decay=self.hp.weight_decay)
        if t == "adam":
            return Adam(p, lr=self.hp.learning_rate, betas=self.hp.betas, eps=self.hp.eps, weight_decay=self.hp.weight_decay)
        if t == "sgd":
            return SGD(p, lr=self.hp.learning_rate, momentum=0.9, nesterov=True, weight_decay=self.hp.weight_decay)
        if t == "adagrad":
            return Adagrad(p, lr=self.hp.learning_rate, eps=self.hp.eps, weight_decay=self.hp.weight_decay)
        raise ValueError(f"Unsupported optimizer: {self.hp.optimizer_type}")

    # â€”â€” ä¸‰é˜¶æ®µå†»ç»“ç­–ç•¥ï¼ˆæŒ‰ä½ çš„æ¨¡å—åè‡ªåŠ¨æ¢æµ‹ï¼‰â€”â€”
    def apply_freeze_by_stage(self):
        if self.stage == 1:
            print("[Stage1] ä¸å†»ç»“ï¼ˆæˆ–ä»…æŒ‰éœ€å†»ç»“å‰ç«¯ï¼‰")
        elif self.stage == 2:
            # å†»ç»“è¯´è¯äººæ¡ä»¶åˆ†æ”¯ï¼ˆå…·ä½“æ¨¡å—åæŒ‰ä½ çš„å®ç°ï¼‰
            if hasattr(self.model, "conditioning_encoder"):
                for p in self.model.conditioning_encoder.parameters(): p.requires_grad = False
                print("[Stage2] å†»ç»“ conditioning_encoderï¼ˆspeaker æ¡ä»¶ï¼‰")
            # æƒ…æ„Ÿåˆ†æ”¯è®¾ä¸ºå¯è®­ç»ƒ
            for name in ["emo_conditioning_encoder", "emo_perceiver_encoder", "emo_layer", "emovec_layer"]:
                if hasattr(self.model, name):
                    for p in getattr(self.model, name).parameters():
                        p.requires_grad = True
                    print(f"[Stage2] è®­ç»ƒ {name}")
        elif self.stage == 3:
            # å†»ç»“æ¡ä»¶åˆ†æ”¯ï¼Œå¾®è°ƒä¸»å¹²/è¾“å‡ºå¤´
            for name in ["conditioning_encoder", "perceiver_encoder", "emo_conditioning_encoder", "emo_perceiver_encoder"]:
                if hasattr(self.model, name):
                    for p in getattr(self.model, name).parameters(): p.requires_grad = False
            print("[Stage3] å†»ç»“æ¡ä»¶åˆ†æ”¯ï¼Œä»…å¾®è°ƒä¸»å¹²/è¾“å‡ºå±‚")
        else:
            raise ValueError("stage å¿…é¡»ä¸º 1/2/3")

    # â€”â€” æ•°æ®åŠ è½½å™¨ â€”â€”
    def build_loaders(self):
        train_ds = T2SDataset(self.hp.train_jsonl, self.tokenizer)
        val_ds   = T2SDataset(self.hp.val_jsonl,   self.tokenizer)
        train_ld = DataLoader(train_ds, batch_size=self.hp.batch_size, shuffle=True,
                              num_workers=self.hp.num_workers, pin_memory=self.hp.pin_memory,
                              collate_fn=collate_fn, drop_last=True)
        val_ld   = DataLoader(val_ds, batch_size=self.hp.val_batch_size, shuffle=False,
                              num_workers=self.hp.num_workers, pin_memory=self.hp.pin_memory,
                              collate_fn=collate_fn, drop_last=False)
        return train_ld, val_ld

    # â€”â€” å‰å‘ï¼šä¸¥æ ¼æŒ‰ UnifiedVoice å…¬å¼€æ–¹æ³•æ„å»º logits â€”â€”
    def forward_get_mel_logits(self, batch) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è¿”å›:
          mel_logits: [B, V_mel, T_mel]  â€”â€” ç›´æ¥ç”¨äº CrossEntropyLoss
          mel_targets: [B, T_mel]
        """
        m = self.model
        device = self.device

        text = batch["text"].to(device)              # [B, T_txt]
        sem_tgt = batch["sem_tgt"].to(device)        # [B, T_mel]
        sem_inp = batch["sem_inp"].to(device)        # [B, T_mel]
        text_len = batch["text_len"].to(device)
        sem_len  = batch["sem_len"].to(device)
        cond_mel = batch["cond_mel"].to(device)      # [B, 1024, F]
        emo_mel  = batch["emo_mel"].to(device)       # [B, 1024, F]
        cond_len = batch["cond_len"].to(device)
        emo_len  = batch["emo_len"].to(device)

        # ===== 1) æ¡ä»¶/æƒ…æ„Ÿå‘é‡ï¼ˆä¿æŒè¾“å…¥ä¸º [B,1024,F]ï¼Œä¸è¦æ‰‹åŠ¨ transposeï¼‰=====
        try:
            # é¦–é€‰ï¼šæ­£å¸¸é€šè¿‡ get_conditioningï¼ˆå·²åœ¨ __init__ å¼ºåˆ¶ perceiverï¼Œæ›´ç¨³ï¼‰
            conds_latent = m.get_conditioning(cond_mel, cond_len)
            # æƒ…æ„Ÿæ”¯è·¯
            emo_vec_ori  = m.get_emo_conditioning(emo_mel, emo_len)
            emo_vec = m.emovec_layer(emo_vec_ori)
            emo_vec = m.emo_layer(emo_vec)
        except Exception as e:
            # ğŸ›Ÿ å…œåº•ï¼šè‹¥ä»å› ç‰ˆæœ¬å·®å¼‚è§¦å‘ conformer å†…éƒ¨å½¢çŠ¶å¼‚å¸¸ï¼Œåˆ™é€€åŒ–ä¸ºâ€œçº¯æƒ…æ„Ÿæ¡ä»¶â€
            print("[WARN] get_conditioning failed, fallback to emo-only latents. err=", repr(e))
            with torch.no_grad():
                emo_vec_ori  = m.get_emo_conditioning(emo_mel, emo_len)
                emo_vec = m.emovec_layer(emo_vec_ori)
                emo_vec = m.emo_layer(emo_vec)              # [B, d_model]
                B = emo_mel.size(0)
                K = getattr(m, "condition_num_latent", 32)
                conds_latent = emo_vec.unsqueeze(1).repeat(1, K, 1)  # [B, K, d_model]

        # ===== 2) æ—¶é•¿/é€Ÿåº¦æ§åˆ¶å‘é‡ï¼ˆä½¿ç”¨ speed_emb çš„è‡ªç”±/å—æ§åŒåµŒå…¥ï¼‰=====
        tmp = torch.zeros(text.size(0), device=device).long()
        duration_emb      = m.speed_emb(tmp)                  # è‡ªç”±
        duration_emb_half = m.speed_emb(torch.ones_like(tmp)) # å—æ§
        if self.stage == 1:
            mask = (torch.rand_like(tmp.float()) < 0.3).long()
            durA = m.speed_emb(mask)
            durB = m.speed_emb(1 - mask)
            conds = torch.cat((conds_latent + emo_vec.unsqueeze(1), durA.unsqueeze(1), durB.unsqueeze(1)), 1)
        else:
            conds = torch.cat((conds_latent + emo_vec.unsqueeze(1), duration_emb_half.unsqueeze(1), duration_emb.unsqueeze(1)), 1)

        # ===== 3) æ–‡æœ¬/è¯­ä¹‰è¾“å…¥è¾“å‡ºå¯¹é½ï¼ˆä½¿ç”¨æ¨¡å‹å†…å·¥å…·å‡½æ•°ï¼‰=====
        text_inputs = m.set_text_padding(text.clone(), text_len)
        text_inputs, _ = m.build_aligned_inputs_and_targets(text_inputs, m.start_text_token, m.stop_text_token)
        text_emb = m.text_embedding(text_inputs) + m.text_pos_embedding(text_inputs)

        mel_codes = m.set_mel_padding(sem_inp.clone(), sem_len)
        mel_codes, mel_targets = m.build_aligned_inputs_and_targets(mel_codes, m.start_mel_token, m.stop_mel_token)
        mel_emb = m.mel_embedding(mel_codes) + m.mel_pos_embedding(mel_codes)

        # ===== 4) å– logits =====
        _, mel_logits = m.get_logits(conds, text_emb, m.text_head, mel_emb, m.mel_head, get_attns=False, return_latent=False)
        return mel_logits, mel_targets

    # â€”â€” è¯„ä¼° â€”â€”ï¼ˆä»¥ CE è¿‘ä¼¼ pplï¼‰
    @torch.no_grad()
    def evaluate(self, loader):
        self.model.eval()
        ce = nn.CrossEntropyLoss(ignore_index=PAD_ID, reduction="sum")
        total_nll, total_tok = 0.0, 0
        for batch in loader:
            mel_logits, mel_targets = self.forward_get_mel_logits(batch)
            nll = ce(mel_logits, mel_targets)  # [B,V,T] vs [B,T]
            total_nll += nll.item()
            total_tok += (mel_targets != PAD_ID).sum().item()
        ppl = math.exp(total_nll / max(1, total_tok)) if total_tok else float("inf")
        self.model.train()
        return ppl, total_nll / max(1, total_tok)

    # â€”â€” è®­ç»ƒå¾ªç¯ â€”â€”ï¼ˆä¸‰é˜¶æ®µåˆä¸€ï¼Œé€šè¿‡ --stage åˆ‡æ¢å†»ç»“ä¸æ—¶é•¿ç­–ç•¥ï¼‰
    def fit(self):
        self.apply_freeze_by_stage()
        train_ld, val_ld = self.build_loaders()

        ce_loss = nn.CrossEntropyLoss(ignore_index=PAD_ID)
        # ä½¿ç”¨ torch.amp æ–°æ¥å£
        scaler = torch.amp.GradScaler('cuda', enabled=self.hp.amp)

        pbar = tqdm(total=self.hp.epochs * len(train_ld), desc=f"T2S-Stage{self.stage}")

        for epoch in range(1, self.hp.epochs + 1):
            for i, batch in enumerate(train_ld, 1):
                self.global_step += 1
                with torch.amp.autocast('cuda', enabled=self.hp.amp):
                    mel_logits, mel_targets = self.forward_get_mel_logits(batch)
                    loss = ce_loss(mel_logits, mel_targets)

                scaler.scale(loss / self.hp.accumulation_steps).backward()

                if self.global_step % self.hp.accumulation_steps == 0:
                    scaler.unscale_(self.optimizer)
                    if self.hp.gradient_clip_norm and self.hp.gradient_clip_norm > 0:
                        clip_grad_norm_(self.model.parameters(), self.hp.gradient_clip_norm)
                    scaler.step(self.optimizer)
                    scaler.update()
                    self.optimizer.zero_grad(set_to_none=True)

                    # æ‰‹å·¥ lr è°ƒåº¦ï¼ˆcosine + warmupï¼‰
                    lr = cosine_with_warmup(self.global_step, self.hp.learning_rate, warmup=4000,
                                            max_steps=max(4000, self.hp.epochs * len(train_ld)))
                    for g in self.optimizer.param_groups: g["lr"] = lr

                if self.global_step % self.hp.log_freq == 0:
                    tqdm.write(f"[LOG] ep={epoch} it={i} step={self.global_step} lr={self.optimizer.param_groups[0]['lr']:.2e} loss={loss.item():.4f}")

                pbar.update(1)

            # éªŒè¯ + æ—©åœ
            if epoch % self.hp.val_freq == 0:
                ppl, nll = self.evaluate(val_ld)
                tqdm.write(f"[EVAL] ep={epoch} ppl={ppl:.3f} nll/token={nll:.4f}")
                improved = nll < self.best_val
                if improved:
                    self.best_val = nll
                    self.save_ckpt(is_best=True, tag=f"best_ep{epoch}")
                else:
                    # æ—©åœè®¡æ•°ï¼ˆå¦‚éœ€ä¸¥æ ¼æ—©åœï¼Œå¯è¡¥è®¡æ•°å™¨ï¼‰
                    pass

            # å¸¸è§„ä¿å­˜
            if epoch % self.hp.save_freq == 0:
                self.save_ckpt(is_best=False, tag=f"ep{epoch}")

        pbar.close()

    def save_ckpt(self, is_best: bool, tag: str):
        path = os.path.join(self.hp.checkpoint_dir, f"t2s_stage{self.stage}_{tag}.pth")
        ckpt = {
            "model": self.model.state_dict(),
            "optimizer": self.optimizer.state_dict(),
            "global_step": self.global_step,
            "best_val": self.best_val,
            "cfg": asdict(self.model_cfg)
        }
        torch.save(ckpt, path)
        print(f"[CKPT] saved -> {path}")
        if is_best:
            best = os.path.join(self.hp.checkpoint_dir, f"t2s_stage{self.stage}_best.pth")
            torch.save(ckpt, best)
            print(f"[CKPT] best -> {best}")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--stage", type=int, default=1, choices=[1,2,3], help="è®­ç»ƒé˜¶æ®µï¼š1|2|3")
    ap.add_argument("--amp", action="store_true", help="å¼€å¯æ··åˆç²¾åº¦ï¼ˆtorch.ampï¼‰")
    args = ap.parse_args()

    trainer = T2STrainer(stage=args.stage)
    # å°†å‘½ä»¤è¡Œçš„ --amp èµ‹å€¼åˆ°è¶…å‚ï¼ˆä¸ç ´ååŸç»“æ„ï¼‰
    object.__setattr__(trainer.hp, "amp", args.amp)

    trainer.fit()

if __name__ == "__main__":
    main()
